{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLhl31GfrS90"
   },
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-WNYYiErIfd"
   },
   "outputs": [],
   "source": [
    "# Data Loading and Numerical Operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualisasi distribusi untuk fitur kategorikal menggunakan bar chart\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Resampling\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Data Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, classification_report\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ensembling\n",
    "# from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "312jDtRbrX0V"
   },
   "source": [
    "## 2. Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "pIfuIirhuwgH",
    "outputId": "81323349-0f0a-46a1-fd4e-35e9c49284c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37079, 51)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading and converting the data into a pandas dataframe\n",
    "df = pd.read_excel(\"C:/Users/ASUS/JupyterNotebook/Machine Learning/Coronary-Heart-Disease-Prediction-master/CardiacPrediction.xlsx\") \n",
    "\n",
    "# Calculating the dimensions of the dataset\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "C456njpsu6fb",
    "outputId": "d43e5f23-f9cc-4891-89fc-97958a00c77c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(df['Age'].max())\n",
    "print(df['Age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37079, 51)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df.drop(columns=['SEQN', 'Gender', 'Annual-Family-Income', 'Ratio-Family-Income-Poverty', 'Height', 'Lymphocyte', 'Monocyte', 'Eosinophils', 'Mean-Cell-Vol', 'Mean-Cell-Hgb-Conc.', 'Segmented-Neutrophils', 'Hematocrit', 'Total-Cholesterol', 'Health-Insurance', 'Vigorous-work', 'Moderate-work', 'Diabetes', 'Blood-Rel-Diabetes', 'Blood-Rel-Stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                              int64\n",
       "X60-sec-pulse                    int64\n",
       "Systolic                         int64\n",
       "Diastolic                        int64\n",
       "Weight                         float64\n",
       "Body-Mass-Index                float64\n",
       "White-Blood-Cells              float64\n",
       "Basophils                      float64\n",
       "Red-Blood-Cells                float64\n",
       "Hemoglobin                     float64\n",
       "Mean-cell-Hemoglobin           float64\n",
       "Platelet-count                 float64\n",
       "Mean-Platelet-Vol              float64\n",
       "Red-Cell-Distribution-Width    float64\n",
       "Albumin                          int64\n",
       "ALP                              int64\n",
       "AST                              int64\n",
       "ALT                              int64\n",
       "Cholesterol                    float64\n",
       "Creatinine                     float64\n",
       "Glucose                        float64\n",
       "GGT                              int64\n",
       "Iron                           float64\n",
       "LDH                              int64\n",
       "Phosphorus                     float64\n",
       "Bilirubin                      float64\n",
       "Protein                        float64\n",
       "Uric.Acid                      float64\n",
       "Triglycerides                  float64\n",
       "HDL                            float64\n",
       "Glycohemoglobin                float64\n",
       "CoronaryHeartDisease             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuFjl_G_NaU8"
   },
   "source": [
    "## 4. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37079, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4noCUHEik9b"
   },
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataframe.drop(['CoronaryHeartDisease'], axis=1) #x atribut yang mempengaruhi CoronaryHeartDisease (independent variable)\n",
    "y = dataframe['CoronaryHeartDisease'] #y atribut label (dependent)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25955, 31)\n",
      "(11124, 31)\n",
      "(25955,)\n",
      "(11124,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35571\n",
       "1     1508\n",
       "Name: CoronaryHeartDisease, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UV6IdsnPjiNV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling imbalanced dataset by oversampling positive cases Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous-multioutput'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12336\\1964027620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# sampling SMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_sampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_sampling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Convert arrays to DataFrame and Series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;34m\"multilabel-sequences\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     ]:\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous-multioutput'"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=30)\n",
    "\n",
    "# sampling SMOTE\n",
    "x_sampling, y_sampling = sm.fit_resample(train_x, test_x)\n",
    "\n",
    "# Convert arrays to DataFrame and Series\n",
    "x_sampling_df = pd.DataFrame(x_sampling, columns=x.columns)\n",
    "y_sampling_series = pd.Series(y_sampling, name=y.name)\n",
    "\n",
    "# Combine the resampled minority class with the majority class\n",
    "resampled_data = pd.concat([x_sampling_df, y_sampling_series], axis=1)\n",
    "\n",
    "# Print the resampled data\n",
    "print(resampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_sampling_series).value_counts().plot(kind='bar', title='Class distribution after applying SMOTE', xlabel='CoronaryHeartDisease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "are_rows_equal = resampled_data.duplicated().any()\n",
    "\n",
    "if are_rows_equal:\n",
    "    print(\"Ada baris yang sama di antara kedua dataframe.\")\n",
    "else:\n",
    "    print(\"Tidak ada baris yang sama di antara kedua dataframe.\")\n",
    "\n",
    "# Mengecek duplikasi setelah resampling\n",
    "print(\"Jumlah baris duplikat setelah resampling:\", resampled_data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Imlks2_BhSYy"
   },
   "source": [
    "# Menghitung korelasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Checking relationship between variables\n",
    "cor=dataframe.corr()\n",
    "plt.figure(figsize=(40,30), facecolor='w')\n",
    "sns.heatmap(cor,xticklabels=cor.columns,yticklabels=cor.columns,annot=True)\n",
    "plt.title(\"Correlation among all the Variables of the Dataset\", size=20)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "5zbWcBxM4O2A",
    "outputId": "75e729a4-580d-4e41-c68b-0a50c55d80d1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Deskripsi statistik dasar untuk fitur kategorikal\n",
    "# print(dataframe.describe())\n",
    "\n",
    "# # Menghitung jumlah nilai unik untuk setiap fitur kategorikal\n",
    "# for col in ['Gender', 'Vigorous-work', 'Moderate-work', 'Health-Insurance', 'Diabetes', 'Blood-Rel-Diabetes', 'Blood-Rel-Stroke']:\n",
    "#     print(f\"Jumlah nilai unik di {col}: {dataframe[col].nunique()}\")\n",
    "#     print(dataframe[col].value_counts())\n",
    "#     print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmFlzKoJs2aK"
   },
   "source": [
    "### a. Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5cQsT7dVDRB"
   },
   "source": [
    "#### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categorical_features = ['Gender', 'Vigorous-work', 'Moderate-work', 'Diabetes', 'Blood-Rel-Diabetes', 'Blood-Rel-Stroke']\n",
    "\n",
    "# for feature in categorical_features:\n",
    "#     print(feature,':')\n",
    "#     print(dataframe[feature].value_counts())\n",
    "#     print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogSfYrgHSR3V",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categorical_features = ['Gender', 'Vigorous-work', 'Moderate-work', 'Diabetes', 'Blood-Rel-Diabetes', 'Blood-Rel-Stroke']\n",
    "# for feature in categorical_features:\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     sns.countplot(x=feature, data=dataframe)\n",
    "#     plt.title(f'Distribusi {feature}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSeAw1Fbr_WB"
   },
   "source": [
    "Diantara fitur kategorikal : \n",
    "* `Vigorous-work`, `diabetes`, `Blood-Rel-Stroke` sangat tidak seimbang.\n",
    "* `Moderate-work` untuk kategori 2 memiliki jumlah tertinggi, yang menunjukkan bahwa mayoritas responden tidak melakukan pekerjaan sedang dan dan kategori 3 (kategori Tidak dapat melakukan aktivitas) memiliki jumlah yang sangat sedikit.\n",
    "* Distribusi `Gender` menunjukkan distribusi yang hampir seimbang antara jenis kelamin dalam sampel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cV6Ef6MGVHVo"
   },
   "source": [
    "#### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisasi distribusi untuk fitur numerikal menggunakan histogram.\n",
    "\n",
    "# numerical_features = ['Age', 'X60-sec-pulse','Systolic', 'Diastolic', 'Weight', 'Body-Mass-Index', 'White-Blood-Cells', \n",
    "#                       'Basophils', 'Red-Blood-Cells', 'Hemoglobin', 'Mean-cell-Hemoglobin', 'Platelet-count',\n",
    "#                       'Mean-Platelet-Vol', 'Red-Cell-Distribution-Width', 'Albumin', 'ALP', 'AST', 'ALT', \n",
    "#                       'Cholesterol', 'Creatinine', 'Glucose', 'GGT', 'Iron', 'LDH', 'Phosphorus', \n",
    "#                       'Bilirubin', 'Protein', 'Uric.Acid', 'Triglycerides', 'HDL', 'Glycohemoglobin',\n",
    "#                       'Diabetes', 'Blood-Rel-Diabetes', 'Blood-Rel-Stroke']\n",
    "\n",
    "# tipe data numerik standar untuk bilangan pecahan dan bilangan bulat.\n",
    "# numerical_features = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Menghapus fitur kategorikal yang mungkin secara tidak sengaja dianggap sebagai numerik\n",
    "# numerical_features = [feature for feature in numerical_features if feature not in numerical_features]\n",
    "\n",
    "# for feature in numerical_features:\n",
    "#     plt.figure(figsize=(6, 3))\n",
    "#     sns.histplot(dataframe[feature], kde=True)\n",
    "#     plt.title(f'Distribusi {feature}')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8701aLrTuQMA"
   },
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "XcLhe_M3uQMB",
    "outputId": "09cfe17d-9d82-4f54-c66d-fd68743d6849"
   },
   "outputs": [],
   "source": [
    "#To idenfify the features that have larger contribution towards the outcome variable, CoronaryHeartDisease\n",
    "X=resampled_data.iloc[:,0:31]\n",
    "y=resampled_data.iloc[:,-1]\n",
    "print(\"X - \", X.shape, \"\\ny - \", y.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbYGYRwDuQMC"
   },
   "outputs": [],
   "source": [
    "#Apply SelectKBest and extract top 10 features\n",
    "best=SelectKBest(score_func=chi2, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIZb9Rs3uQME"
   },
   "outputs": [],
   "source": [
    "fit=best.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmxaYawDuQMG"
   },
   "outputs": [],
   "source": [
    "data_scores=pd.DataFrame(fit.scores_)\n",
    "data_columns=pd.DataFrame(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "wkdajonQuQMI",
    "outputId": "c2a92ea5-4900-442b-f70e-75c95bb36f4b"
   },
   "outputs": [],
   "source": [
    "#Join the two dataframes\n",
    "scores=pd.concat([data_columns,data_scores],axis=1)\n",
    "scores.columns=['Feature','Score']\n",
    "print(scores.nlargest(20,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "W9pAT3Q2uQMK",
    "outputId": "72d85145-7622-4fe5-dae1-f2488ed67d43"
   },
   "outputs": [],
   "source": [
    "#To visualize feature selection\n",
    "scores=scores.sort_values(by=\"Score\", ascending=False)\n",
    "plt.figure(figsize=(20,7), facecolor='w')\n",
    "sns.barplot(x='Score',y='Feature',data=scores,palette='BuGn_r')\n",
    "plt.title(\"Plot showing the best features in descending order\", size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGtQ2K2_uQMN"
   },
   "source": [
    "This plot shows the `Features` and their respective `chi-square test` scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "BvArAN-ruQMN",
    "outputId": "4bb8ac9d-9db9-4feb-b730-ed2a64d99062",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select 10 features\n",
    "features=scores[\"Feature\"].tolist()[:10]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "IP3LZYW_uQMP",
    "outputId": "0eab9b89-7eeb-4148-961f-69e1b336e7d8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=dataframe[['Age','Uric.Acid','Creatinine','Platelet-count','LDH','X60-sec-pulse','Systolic','Diastolic','ALT','Glucose','CoronaryHeartDisease']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqP92LggUmey"
   },
   "source": [
    "## Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "ErDa8qUauQJ5",
    "outputId": "94d5cad9-a225-48dc-99b8-89c9eba829bc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Distribution of outcome variable, Heart Disease\n",
    "plt.figure(figsize=(8, 6), facecolor='w')\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "# Set the color palette\n",
    "custom_palette = [\"steelBlue\", \"salmon\"]\n",
    "\n",
    "#first subplot\n",
    "plt.subplot(121)\n",
    "sns.countplot(x=\"CoronaryHeartDisease\", data=dataframe, palette=custom_palette)\n",
    "\n",
    "plt.title(\"Count distribution of coronaryHeartDisease\", size=15)\n",
    "\n",
    "\n",
    "#first subplot\n",
    "plt.subplot(122)\n",
    "labels=[0,1]\n",
    "plt.pie(data[\"CoronaryHeartDisease\"].value_counts(),autopct=\"%1.1f%%\",labels=labels,colors=[\"steelBlue\",\"salmon\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3o2D6PAalNWQ"
   },
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFa9NRy6lRB-"
   },
   "source": [
    "We use the following different machine learning models for the dataset:\n",
    "\n",
    "1. Random Forest Classifier\n",
    "2. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "l50O5z3lquhO",
    "outputId": "9017f45b-6ef3-464c-c427-e6c016992056"
   },
   "outputs": [],
   "source": [
    "m3 = 'Random Forest Classfier'\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=0,max_depth=12)\n",
    "rf.fit(train_x,train_y)\n",
    "rf_predicted = rf.predict(test_x)\n",
    "rf_conf_matrix = confusion_matrix(test_y, rf_predicted)\n",
    "rf_acc_score = accuracy_score(test_y, rf_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\n",
    "print(classification_report(test_y,rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "jDes7RVtijxd",
    "outputId": "4a136bce-da68-4c23-9939-ddb3a4183ffb"
   },
   "outputs": [],
   "source": [
    "m5 = 'Gradient Boosting Classifier'\n",
    "gvc =  GradientBoostingClassifier()\n",
    "gvc.fit(train_x,train_y)\n",
    "gvc_predicted = gvc.predict(test_x)\n",
    "gvc_conf_matrix = confusion_matrix(test_y, gvc_predicted)\n",
    "gvc_acc_score = accuracy_score(test_y, gvc_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(gvc_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Gradient Boosting Classifier:\",gvc_acc_score*100,'\\n')\n",
    "print(classification_report(test_y,gvc_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JEIHuxdAqXzk"
   },
   "source": [
    "## Hyperparameter Tuning for best Classifier\n",
    "#### Using Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__aVZxHoEZJs"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rqoTIlgTp3pV",
    "outputId": "11924aee-2dc8-4fae-9266-d55e17f20b49"
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "vFve0sbSqipF",
    "outputId": "b10da127-8f42-4538-d067-b175852fc9ea"
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 10, \n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               random_state=7, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yduUIfEOqrUE"
   },
   "outputs": [],
   "source": [
    "rf_hyper = rf_random.best_estimator_\n",
    "rf_hyper.fit(train_x,train_y)\n",
    "print(\"Accuracy on training set is : {}\".format(rf_hyper.score(train_x,train_y)))\n",
    "print(\"Accuracy on validation set is : {}\".format(rf_hyper.score(test_x, test_y)))\n",
    "rf_predicted = rf_hyper.predict(test_x)\n",
    "rf_acc_score = accuracy_score(test_y, rf_predicted)\n",
    "print(\"Accuracy of Hyper-tuned Random Forest Classifier:\",rf_acc_score*100,'\\n')\n",
    "print(classification_report(test_y, rf_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytvEZdPzEjol"
   },
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VZbUP-juQMw"
   },
   "outputs": [],
   "source": [
    "#Number of trees\n",
    "n_estimators = [int(i) for i in np.linspace(start=100,stop=1000,num=10)]\n",
    "#Number of features to consider at every split\n",
    "max_features = ['auto','sqrt']\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [int(i) for i in np.linspace(10, 100, num=10)]\n",
    "max_depth.append(None)\n",
    "#Minimum number of samples required to split a node\n",
    "min_samples_split=[2,5,10]\n",
    "#Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,4]\n",
    "\n",
    "#Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rH19GbvuQMz"
   },
   "outputs": [],
   "source": [
    "gb=GradientBoostingClassifier(random_state=0)\n",
    "#Random search of parameters, using 3 fold cross validation, \n",
    "#search across 100 different combinations\n",
    "gb_random = RandomizedSearchCV(estimator=gb, param_distributions=random_grid,\n",
    "                              n_iter=10, scoring='f1', \n",
    "                              cv=3, verbose=2, random_state=0, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "gb_random.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5-sJOH2E4pJ"
   },
   "outputs": [],
   "source": [
    "gb_hyper = gb_random.best_estimator_\n",
    "gb_hyper.fit(train_x,train_y)\n",
    "print(\"Accuracy on training set is : {}\".format(gb_hyper.score(train_x,train_y)))\n",
    "print(\"Accuracy on validation set is : {}\".format(gb_hyper.score(test_x, test_y)))\n",
    "gbc_predicted = gb_hyper.predict(test_x)\n",
    "gbc_acc_score = accuracy_score(test_y, gbc_predicted)\n",
    "print(\"Accuracy of Hyper-tuned Gradient Boosting Classifier:\",gbc_acc_score*100,'\\n')\n",
    "print(classification_report(test_y, gbc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of neighbors\n",
    "n_neighbors = np.arange(1, 10)\n",
    "#Number of weights\n",
    "weights = ['uniform','distance']\n",
    "#metric\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "\n",
    "#Create the random grid\n",
    "random_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  # Berbagai nilai untuk n_neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Pilihan untuk jenis bobot\n",
    "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Pilihan untuk algoritma\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],  # Pilihan metrik jarak\n",
    "#     'p': [1, 2],  # Nilai p untuk metrik Minkowski\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Inisialisasi RandomizedSearchCV\n",
    "knn_random = RandomizedSearchCV(estimator=knn, param_distributions=random_grid,\n",
    "                                   n_iter=100,  # Jumlah kombinasi yang akan diuji\n",
    "                                   scoring='f1',  # Metrik evaluasi yang digunakan\n",
    "                                   cv=3,  # Jumlah lipatan validasi silang (cross-validation)\n",
    "                                   verbose=2,  # Tingkat verbosity\n",
    "                                   n_jobs=-1,  # Menggunakan semua CPU yang tersedia\n",
    "                                   random_state=0,  # Seed untuk reproduksi\n",
    "                                   return_train_score=True)\n",
    "\n",
    "# Melatih model dengan pencarian acak\n",
    "knn_random.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper = knn_random.best_estimator_\n",
    "knn_hyper.fit(train_x,train_y)\n",
    "print(\"Accuracy on training set is : {}\".format(knn_hyper.score(train_x,train_y)))\n",
    "print(\"Accuracy on validation set is : {}\".format(knn_hyper.score(test_x, test_y)))\n",
    "knnc_predicted = knn_hyper.predict(test_x)\n",
    "knnc_acc_score = accuracy_score(test_y, knnc_predicted)\n",
    "print(\"Accuracy of Hyper-tuned K Nearest Neighbor:\",knn_acc_score*100,'\\n')\n",
    "print(classification_report(test_y, knnc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-08-25T04:34:33.803133Z",
     "iopub.status.busy": "2020-08-25T04:34:33.794637Z",
     "iopub.status.idle": "2020-08-25T04:34:34.194787Z",
     "shell.execute_reply": "2020-08-25T04:34:34.194128Z"
    },
    "id": "fKlA49uXxFnj",
    "papermill": {
     "duration": 0.477511,
     "end_time": "2020-08-25T04:34:34.194956",
     "exception": false,
     "start_time": "2020-08-25T04:34:33.717445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_false_positive_rate,lr_true_positive_rate,lr_threshold = roc_curve(test_y,lr_predict)\n",
    "knn_false_positive_rate,knn_true_positive_rate,knn_threshold = roc_curve(test_y,knn_predict)\n",
    "rf_false_positive_rate,rf_true_positive_rate,rf_threshold = roc_curve(test_y,rf_predicted)                                                             \n",
    "dt_false_positive_rate,dt_true_positive_rate,dt_threshold = roc_curve(test_y,dt_predicted)\n",
    "gbc_false_positive_rate,gbc_true_positive_rate,gbc_threshold = roc_curve(test_y,gbc_predicted)\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(15,8), facecolor='w')\n",
    "plt.title('Reciever Operating Characterstic Curve')\n",
    "plt.plot(lr_false_positive_rate,lr_true_positive_rate,label='Logistic Regression')\n",
    "plt.plot(knn_false_positive_rate,knn_true_positive_rate,label='K-Nearest Neighbor')\n",
    "plt.plot(rf_false_positive_rate,rf_true_positive_rate,label='Random Forest')\n",
    "plt.plot(dt_false_positive_rate,dt_true_positive_rate,label='Desion Tree')\n",
    "plt.plot(gbc_false_positive_rate,gbc_true_positive_rate,label='Gradient Boosting Classifier')\n",
    "plt.plot([0,1],ls='--')\n",
    "plt.plot([0,0],[1,0],c='.5')\n",
    "plt.plot([1,1],c='.5')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtO1mHWZMX5j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shEFOD3uxFnm",
    "papermill": {
     "duration": 0.074498,
     "end_time": "2020-08-25T04:34:34.358046",
     "exception": false,
     "start_time": "2020-08-25T04:34:34.283548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-08-25T04:34:34.520633Z",
     "iopub.status.busy": "2020-08-25T04:34:34.519603Z",
     "iopub.status.idle": "2020-08-25T04:34:34.527420Z",
     "shell.execute_reply": "2020-08-25T04:34:34.526637Z"
    },
    "id": "UzENa_fkxFnm",
    "papermill": {
     "duration": 0.097048,
     "end_time": "2020-08-25T04:34:34.527566",
     "exception": false,
     "start_time": "2020-08-25T04:34:34.430518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ev = pd.DataFrame({'Model': ['Logistic Regression','K-Nearest Neighbour','Random Forest',\n",
    "                                   'Decision Tree','Gradient Boosting'], 'Accuracy': [lr_acc_score*100, knn_acc_score*100, \n",
    "                                                                                      rf_acc_score*100, dt_acc_score*100,gbc_acc_score*100]})\n",
    "model_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-08-25T04:34:34.689417Z",
     "iopub.status.busy": "2020-08-25T04:34:34.682642Z",
     "iopub.status.idle": "2020-08-25T04:34:34.902639Z",
     "shell.execute_reply": "2020-08-25T04:34:34.901837Z"
    },
    "id": "Hj0Oeg6qxFno",
    "papermill": {
     "duration": 0.302638,
     "end_time": "2020-08-25T04:34:34.902774",
     "exception": false,
     "start_time": "2020-08-25T04:34:34.600136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = ['red','green','blue','gold','silver']\n",
    "plt.figure(figsize=(15,8), facecolor='w')\n",
    "plt.title(\"Barplot Representing Accuracy of different models\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.bar(model_ev['Model'],model_ev['Accuracy'],color = colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHoqMC5CxFnq",
    "papermill": {
     "duration": 0.071054,
     "end_time": "2020-08-25T04:34:35.045063",
     "exception": false,
     "start_time": "2020-08-25T04:34:34.974009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensembling\n",
    "\n",
    "In order to increase the accuracy of the model we use ensembling. Here we use stacking technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-08-25T04:34:35.202862Z",
     "iopub.status.busy": "2020-08-25T04:34:35.201683Z",
     "iopub.status.idle": "2020-08-25T04:34:35.435634Z",
     "shell.execute_reply": "2020-08-25T04:34:35.436403Z"
    },
    "id": "vpCR1d-ZxFnq",
    "papermill": {
     "duration": 0.319482,
     "end_time": "2020-08-25T04:34:35.436693",
     "exception": false,
     "start_time": "2020-08-25T04:34:35.117211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scv=StackingCVClassifier(classifiers=[rf_hyper, gb_hyper, knn], meta_classifier= rf)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "scv.fit(train_x.values,train_y.values)\n",
    "scv_predicted = scv.predict(test_x)\n",
    "scv_conf_matrix = confusion_matrix(test_y, scv_predicted)\n",
    "scv_acc_score = accuracy_score(test_y, scv_predicted)\n",
    "scv_rec_score = recall_score(test_y, scv_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(scv_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of StackingCVClassifier:\",scv_acc_score*100,'\\n')\n",
    "print(\"Recall of StackingCVClassifier:\",scv_rec_score*100,'\\n')\n",
    "\n",
    "print(classification_report(test_y,scv_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv=StackingCVClassifier(classifiers=[rf_hyper, gb_hyper], meta_classifier= rf)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "scv.fit(train_x.values,train_y.values)\n",
    "scv_predicted = scv.predict(test_x)\n",
    "scv_conf_matrix = confusion_matrix(test_y, scv_predicted)\n",
    "scv_acc_score = accuracy_score(test_y, scv_predicted)\n",
    "scv_rec_score = recall_score(test_y, scv_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(scv_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of StackingCVClassifier:\",scv_acc_score*100,'\\n')\n",
    "print(\"Recall of StackingCVClassifier:\",scv_rec_score*100,'\\n')\n",
    "\n",
    "print(classification_report(test_y,scv_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPJhqGz2taCp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Heart Disease Prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
